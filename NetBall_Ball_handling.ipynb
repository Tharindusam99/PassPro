{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tharindusam99/PassPro/blob/Ball-Handling-Skill-Analyser/NetBall_Ball_handling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDv-TcCnhC30",
        "outputId": "33260cce-0af2-4d3c-94b2-8ff43345d30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExTAyNNrhGDK",
        "outputId": "2cadcb78-f5de-4279-eded-55a67d2076b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.18 sounddevice-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose = mp.solutions.pose"
      ],
      "metadata": {
        "id": "98yiJk1ohIU3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "\n",
        "# Setup mediapipe instance\n",
        "mp_pose = mp.solutions.pose\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "def get_joint_coordinates(landmarks, joint_name, width, height):\n",
        "    \"\"\"Convert normalized coordinates to pixel coordinates\"\"\"\n",
        "    landmark = landmarks[joint_name.value]\n",
        "    return {\n",
        "        'x': int(landmark.x * width),\n",
        "        'y': int(landmark.y * height),\n",
        "        'z': round(landmark.z, 3),\n",
        "        'visibility': round(landmark.visibility, 2)\n",
        "    }\n",
        "\n",
        "def add_title_bar(image, title, bar_height=60, bg_color=(245, 117, 16)):\n",
        "    \"\"\"Add a title bar to the top of the image\"\"\"\n",
        "    h, w = image.shape[:2]\n",
        "    # Create title bar\n",
        "    title_bar = np.full((bar_height, w, 3), bg_color, dtype=np.uint8)\n",
        "\n",
        "    # Add text to title bar\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 1\n",
        "    font_thickness = 2\n",
        "    text_color = (255, 255, 255)\n",
        "\n",
        "    # Get text size to center it\n",
        "    text_size = cv2.getTextSize(title, font, font_scale, font_thickness)[0]\n",
        "    text_x = (w - text_size[0]) // 2\n",
        "    text_y = (bar_height + text_size[1]) // 2\n",
        "\n",
        "    cv2.putText(title_bar, title, (text_x, text_y), font, font_scale, text_color, font_thickness)\n",
        "\n",
        "    # Combine title bar with image\n",
        "    return np.vstack((title_bar, image))\n",
        "\n",
        "# Initialize VideoCapture\n",
        "input_path = r\"/content/drive/MyDrive/Net ball Project/VID-20241011-WA0005.mp4\"\n",
        "output_path = r\"/content/drive/MyDrive/Net ball Project/Pose Estimation.mp4\"\n",
        "video_title = \"Netball Player Joint Analysis - Ball handling analysis\"\n",
        "\n",
        "cap = cv2.VideoCapture(input_path)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Calculate dimensions for the combined frame (original video + info display)\n",
        "combined_width = width + 400  # 400 is the width of info display\n",
        "title_bar_height = 60  # Height of the title bar\n",
        "combined_height = height + title_bar_height  # Add title bar height\n",
        "\n",
        "# Initialize video writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (combined_width, combined_height))\n",
        "\n",
        "# Dictionary of joints to track\n",
        "joints_to_track = {\n",
        "\n",
        "    'LEFT_ELBOW': mp_pose.PoseLandmark.LEFT_ELBOW,\n",
        "    'RIGHT_ELBOW': mp_pose.PoseLandmark.RIGHT_ELBOW,\n",
        "    'LEFT_WRIST': mp_pose.PoseLandmark.LEFT_WRIST,\n",
        "    'RIGHT_WRIST': mp_pose.PoseLandmark.RIGHT_WRIST,\n",
        "    'LEFT_HIP': mp_pose.PoseLandmark.LEFT_HIP,\n",
        "    'RIGHT_HIP': mp_pose.PoseLandmark.RIGHT_HIP,\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "# Setup mediapipe instance\n",
        "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    current_frame = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        current_frame += 1\n",
        "        if current_frame % 10 == 0:  # Print progress every 10 frames\n",
        "            print(f\"Processing frame {current_frame} of {frame_count} ({(current_frame/frame_count*100):.1f}%)\")\n",
        "\n",
        "\n",
        "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        image.flags.writeable = False\n",
        "\n",
        "        results = pose.process(image)\n",
        "\n",
        "        image.flags.writeable = True\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Extract landmarks\n",
        "        try:\n",
        "            landmarks = results.pose_landmarks.landmark\n",
        "\n",
        "            # Create background for joint coordinates display\n",
        "            info_display = np.zeros((height, 400, 3), dtype=np.uint8)\n",
        "            y_offset = 30\n",
        "\n",
        "            # Display joint coordinates\n",
        "            for joint_name, landmark_id in joints_to_track.items():\n",
        "                coords = get_joint_coordinates(landmarks, landmark_id, width, height)\n",
        "\n",
        "                # Display joint information on the side panel\n",
        "                text = f\"{joint_name}: x={coords['x']}, y={coords['y']}, z={coords['z']}\"\n",
        "                cv2.putText(info_display, text, (10, y_offset),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
        "                y_offset += 30\n",
        "\n",
        "                # Mark joint position on the main image\n",
        "                cv2.circle(image, (coords['x'], coords['y']), 5, (0, 255, 0), -1)\n",
        "                cv2.putText(image, joint_name, (coords['x'] + 10, coords['y']),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in frame {current_frame}: {e}\")\n",
        "            pass\n",
        "\n",
        "        # Render pose detection\n",
        "        mp_drawing.draw_landmarks(\n",
        "            image,\n",
        "            results.pose_landmarks,\n",
        "            mp_pose.POSE_CONNECTIONS,\n",
        "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
        "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
        "        )\n",
        "\n",
        "        # Combine main image and info display\n",
        "        combined_image = np.hstack((image, info_display))\n",
        "\n",
        "        # Add title bar to the combined image\n",
        "        final_image = add_title_bar(combined_image, video_title)\n",
        "\n",
        "        # Write the frame to output video\n",
        "        out.write(final_image)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\"Video processing completed! Output saved to:\", output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tROkrjpfhIcb",
        "outputId": "8939f64c-cb1e-40b9-850d-2c496d0b8105"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing frame 10 of 361 (2.8%)\n",
            "Processing frame 20 of 361 (5.5%)\n",
            "Processing frame 30 of 361 (8.3%)\n",
            "Processing frame 40 of 361 (11.1%)\n",
            "Processing frame 50 of 361 (13.9%)\n",
            "Processing frame 60 of 361 (16.6%)\n",
            "Processing frame 70 of 361 (19.4%)\n",
            "Processing frame 80 of 361 (22.2%)\n",
            "Processing frame 90 of 361 (24.9%)\n",
            "Processing frame 100 of 361 (27.7%)\n",
            "Processing frame 110 of 361 (30.5%)\n",
            "Processing frame 120 of 361 (33.2%)\n",
            "Processing frame 130 of 361 (36.0%)\n",
            "Processing frame 140 of 361 (38.8%)\n",
            "Processing frame 150 of 361 (41.6%)\n",
            "Processing frame 160 of 361 (44.3%)\n",
            "Processing frame 170 of 361 (47.1%)\n",
            "Processing frame 180 of 361 (49.9%)\n",
            "Processing frame 190 of 361 (52.6%)\n",
            "Processing frame 200 of 361 (55.4%)\n",
            "Processing frame 210 of 361 (58.2%)\n",
            "Processing frame 220 of 361 (60.9%)\n",
            "Processing frame 230 of 361 (63.7%)\n",
            "Processing frame 240 of 361 (66.5%)\n",
            "Processing frame 250 of 361 (69.3%)\n",
            "Processing frame 260 of 361 (72.0%)\n",
            "Processing frame 270 of 361 (74.8%)\n",
            "Processing frame 280 of 361 (77.6%)\n",
            "Processing frame 290 of 361 (80.3%)\n",
            "Processing frame 300 of 361 (83.1%)\n",
            "Processing frame 310 of 361 (85.9%)\n",
            "Processing frame 320 of 361 (88.6%)\n",
            "Processing frame 330 of 361 (91.4%)\n",
            "Processing frame 340 of 361 (94.2%)\n",
            "Processing frame 350 of 361 (97.0%)\n",
            "Processing frame 360 of 361 (99.7%)\n",
            "Video processing completed! Output saved to: /content/drive/MyDrive/Net ball Project/Pose Estimation.mp4\n"
          ]
        }
      ]
    }
  ]
}